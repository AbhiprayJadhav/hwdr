{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhiprayJadhav/hwdr/blob/main/hwdr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install flask-ngrok pyngrok\n",
        "! ngrok authtoken 2N62QpG3jcBIiWn9PowX7tTQ8k9_4pF1heJVDHkPbVDVCaajL\n",
        "! git clone https://github.com/AbhiprayJadhav/hwdr.git\n",
        "! ls\n",
        "%cd hwdr\n",
        "! ls"
      ],
      "metadata": {
        "id": "fxLheix9Z8cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, base64, config, matplotlib\n",
        "import numpy as np, matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from train import MnistModel\n",
        "from flask import Flask, request, render_template, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "MODEL = None\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "run_with_ngrok(app)\n",
        "\n",
        "class SaveOutput:\n",
        "    def __init__(self):\n",
        "        self.outputs = []\n",
        "\n",
        "    def __call__(self, module, module_in, module_out):\n",
        "        self.outputs.append(module_out)\n",
        "\n",
        "    def clear(self):\n",
        "        self.outputs = []\n",
        "\n",
        "\n",
        "def register_hook():\n",
        "    save_output = SaveOutput()\n",
        "    hook_handles = []\n",
        "\n",
        "    for layer in MODEL.modules():\n",
        "        if isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
        "            handle = layer.register_forward_hook(save_output)\n",
        "            hook_handles.append(handle)\n",
        "    return save_output\n",
        "\n",
        "\n",
        "def module_output_to_numpy(tensor):\n",
        "    return tensor.detach().to('cpu').numpy()\n",
        "\n",
        "\n",
        "def autolabel(rects, ax):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{0:.2f}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "\n",
        "def prob_img(probs):\n",
        "    fig, ax = plt.subplots()\n",
        "    rects = ax.bar(range(len(probs)), probs)\n",
        "    ax.set_xticks(range(len(probs)), (0, 1, 2, 3, 4, 5, 6, 7, 8, 9))\n",
        "    ax.set_ylim(0, 110)\n",
        "    ax.set_title('Probability % of Digit by Model')\n",
        "    autolabel(rects, ax)\n",
        "    probimg = BytesIO()\n",
        "    fig.savefig(probimg, format='png')\n",
        "    probencoded = base64.b64encode(probimg.getvalue()).decode('utf-8')\n",
        "    return probencoded\n",
        "\n",
        "\n",
        "def interpretability_img(save_output):\n",
        "    images = module_output_to_numpy(save_output.outputs[0])\n",
        "    with plt.style.context(\"seaborn-white\"):\n",
        "        fig, _ = plt.subplots(figsize=(20, 20))\n",
        "        plt.suptitle(\"Interpretability by Model\", fontsize=50)\n",
        "        for idx in range(16):\n",
        "            plt.subplot(4, 4, idx+1)\n",
        "            plt.imshow(images[0, idx])\n",
        "        plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "    interpretimg = BytesIO()\n",
        "    fig.savefig(interpretimg, format='png')\n",
        "    interpretencoded = base64.b64encode(\n",
        "        interpretimg.getvalue()).decode('utf-8')\n",
        "    return interpretencoded\n",
        "\n",
        "\n",
        "def mnist_prediction(img):\n",
        "    save_output = register_hook()\n",
        "    img = img.to(DEVICE, dtype=torch.float)\n",
        "    outputs = MODEL(x=img)\n",
        "\n",
        "    probs = torch.exp(outputs.data)[0] * 100\n",
        "    probencoded = prob_img(probs)\n",
        "    interpretencoded = interpretability_img(save_output)\n",
        "\n",
        "    _, output = torch.max(outputs.data, 1)\n",
        "    pred = module_output_to_numpy(output)\n",
        "    return pred[0], probencoded, interpretencoded\n",
        "\n",
        "\n",
        "@app.route(\"/process\", methods=[\"GET\", \"POST\"])\n",
        "def process():\n",
        "    data_url = str(request.get_data())\n",
        "    offset = data_url.index(',')+1\n",
        "    img_bytes = base64.b64decode(data_url[offset:])\n",
        "    img = Image.open(BytesIO(img_bytes))\n",
        "    img = img.convert('L')\n",
        "    img = img.resize((28, 28))\n",
        "    # img.save(r'templates\\image.png')\n",
        "    img = np.array(img)\n",
        "    img = img.reshape((1, 28, 28))\n",
        "    img = torch.tensor(img, dtype=torch.float).unsqueeze(0)\n",
        "\n",
        "    data, probencoded, interpretencoded = mnist_prediction(img)\n",
        "\n",
        "    response = {\n",
        "        'data': str(data),\n",
        "        'probencoded': str(probencoded),\n",
        "        'interpretencoded': str(interpretencoded),\n",
        "    }\n",
        "    return jsonify(response)\n",
        "\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def start():\n",
        "    return render_template(\"default.html\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL = MnistModel(classes=10)\n",
        "    MODEL.load_state_dict(torch.load(\n",
        "        'checkpoint/mnist.pt', map_location=DEVICE))\n",
        "    MODEL.to(DEVICE)\n",
        "    MODEL.eval()\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "LoLHFXqnncR-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}